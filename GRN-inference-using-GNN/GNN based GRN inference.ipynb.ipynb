{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_J0CLolKV-K"
   },
   "source": [
    "#INSTALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9327,
     "status": "ok",
     "timestamp": 1707369388619,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "k6vv4lFAKan7",
    "outputId": "c128e464-3ba1-4316-ca98-66187eec5b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy-ml\n",
      "  Downloading numpy_ml-0.1.2-py2.py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.9/239.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from numpy-ml) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from numpy-ml) (1.11.4)\n",
      "Installing collected packages: numpy-ml\n",
      "Successfully installed numpy-ml-0.1.2\n"
     ]
    }
   ],
   "source": [
    "pip install numpy-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5LNfVBRKgcB"
   },
   "source": [
    "#IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21657,
     "status": "ok",
     "timestamp": 1707369410263,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "RZgCUfgtKjfS"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import convert\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch_geometric.transforms as T\n",
    "#import tensorflow as tf\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import seaborn as sns\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn import HypergraphConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#FOR VISUALIZING GRAPH\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "from collections import Counter\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
    "from sklearn.metrics import DetCurveDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1707369410263,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "jShx8-uEKn67",
    "outputId": "9cf8ff38-0c46-4224-cb45-ae5ab482e0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows=999\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vg4_mbLcRel"
   },
   "source": [
    "#FUNCTION CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707369410263,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "nm5UMAukcTH_"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, hidden1_channels, hidden2_channels,out_channels,dec,af_val,num_layers,epoch,aggr,var):\n",
    "\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        if(var==\"ChebConv\"):\n",
    "          self.convs.append(eval(var)(in_channels, hidden1_channels,aggr=aggr,K=3))\n",
    "          for _ in range(num_layers - 2):\n",
    "              self.convs.append(eval(var)(hidden1_channels, hidden1_channels,aggr=aggr,K=3))\n",
    "          self.convs.append(eval(var)(hidden1_channels, out_channels,aggr=aggr,K=3))\n",
    "        else:\n",
    "          self.convs.append(eval(var)(in_channels, hidden1_channels,aggr=aggr))\n",
    "          for _ in range(num_layers - 2):\n",
    "              self.convs.append(eval(var)(hidden1_channels, hidden1_channels,aggr=aggr))\n",
    "          self.convs.append(eval(var)(hidden1_channels, out_channels,aggr=aggr))\n",
    "\n",
    "\n",
    "    def encode(self, x, edge_index,af_val):\n",
    "        prev_x = None\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)   \n",
    "        for i,conv in enumerate(self.convs[:-1]):\n",
    "            prev_x = x\n",
    "            x = conv(x, edge_index)\n",
    "            if i > 0:\n",
    "              x = x + prev_x\n",
    "            x = eval(af_val)(x)\n",
    "            # x = F.dropout(x, p=.2, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def decode(self, z, edge_label_index,dec):\n",
    "        '''TYPE 1 - Multiplying and adding node embeddings'''\n",
    "        '''TYPE 2 - Cosine similarity'''\n",
    "        '''TYPE 2 - Neural Network'''\n",
    "        if(dec==\"dot_sum\") :\n",
    "          return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
    "            dim=-1)\n",
    "        else:\n",
    "          cos = torch.nn.CosineSimilarity(dim=1)\n",
    "          output = cos(z[edge_label_index[0]].float(), z[edge_label_index[1]].float())\n",
    "          return output\n",
    "\n",
    "\n",
    "def train_link_predictor(\n",
    "    model, train_data, val_data, optimizer, criterion, n_epochs,af_val,dec\n",
    "):\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index,af_val)\n",
    "        positive_num = train_data.edge_index.shape[1]\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=train_data.edge_index,\n",
    "            num_nodes=train_data.num_nodes,\n",
    "            method='sparse'\n",
    "        ).to(device)\n",
    "        edge_label_index = torch.cat(\n",
    "            [train_data.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        ).to(device)\n",
    "        edge_label = torch.cat([\n",
    "            train_data.edge_label,\n",
    "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0).to(device)\n",
    "\n",
    "\n",
    "        out1 = model.decode(z, edge_label_index,dec)\n",
    "        out = out1.view(-1)\n",
    "        loss = criterion(out, edge_label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc,precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k = eval_link_predictor(model, val_data,af_val,dec)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model, data,af_val,dec):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x.to(device), data.edge_index.to(device), af_val)\n",
    "    out = model.decode(z, data.edge_label_index.to(device), dec)#.view(-1)\n",
    "    actual = data.edge_label.cpu().numpy()\n",
    "    auc = roc_auc_score(actual, out.cpu().numpy())\n",
    "    fpr, tpr, _ = roc_curve(actual, out.cpu().numpy())\n",
    "    precision, recall, thresholds = precision_recall_curve(actual, out.cpu().numpy())\n",
    "\n",
    "    pred =out.cpu().numpy()\n",
    "    pred[pred > 0.5] = 1\n",
    "    pred[pred <= 0.5] = 0\n",
    "\n",
    "    mcc = matthews_corrcoef(actual, pred)\n",
    "    jac_score = jaccard_score(actual, pred)\n",
    "    cohkap_score = cohen_kappa_score(actual, pred)\n",
    "    f1 = f1_score(actual, pred)\n",
    "    top_k = top_k_accuracy_score(actual, pred, k=1)\n",
    "\n",
    "    return auc,precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k\n",
    "\n",
    "@torch.no_grad()\n",
    "def prediction(model, data,af_val,dec):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x.to(device), data.edge_index.to(device), af_val)\n",
    "    out = model.decode(z, data.edge_label_index.to(device), dec)#.view(-1)\n",
    "    pred =out.cpu().numpy()\n",
    "    pred[pred > 0.5] = 1\n",
    "    pred[pred <= 0.5] = 0\n",
    "    print(pred)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1707370269648,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "5kkb2LjIcgzd"
   },
   "outputs": [],
   "source": [
    "def main_run(folder_name,file_hetero,file_gold,hidden1_channels,hidden2_channels,out_channels,data,org,ds,dec,af_val,num_layers,epoch,aggr,var):\n",
    "  auprs =0\n",
    "  aucs =0\n",
    "\n",
    "  for i in range(10) :\n",
    "    # print(\"i is : \", i)\n",
    "    split = T.RandomLinkSplit(\n",
    "        num_val=0.2,\n",
    "        num_test=0.3,\n",
    "        is_undirected=False,\n",
    "        add_negative_train_samples=True,\n",
    "        key=\"edge_label\"\n",
    "        # edge_types=('source', 'interaction', 'target'),\n",
    "        # neg_sampling_ratio=8684\n",
    "    )\n",
    "\n",
    "    train_data, val_data, test_data = split(data)\n",
    "    index=(train_data.edge_label == 1).nonzero(as_tuple=True)[0]\n",
    "    ''' OLD CODE'''\n",
    "    in_channels=data.num_features\n",
    "\n",
    "    model =  Net(in_channels, hidden1_channels, hidden2_channels, out_channels,dec,af_val,num_layers,epoch,aggr,var).to(device)#Net(data.num_features, data.num_features, 128, 64).to(device) #self, in_channels, hidden1_channels, hidden2_channels,out_channels\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)#RMSprop(params=model.parameters())#\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion,epoch,af_val,dec).to(device)\n",
    "\n",
    "    test_auc, precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k = eval_link_predictor(model, test_data,af_val,dec)\n",
    "\n",
    "\n",
    "    # tprs.append(tpr)\n",
    "    # fprs.append(fpr)\n",
    "    aucs = aucs+test_auc\n",
    "    aupr = auc(recall, precision)\n",
    "    auprs=auprs+aupr\n",
    "\n",
    "  mean_auc = float(aucs/10)\n",
    "  mean_aupr = float(auprs/10)\n",
    "\n",
    "\n",
    "  list1 = [org, ds, dec, af_val,num_layers, epoch, aggr, var,mean_auc, mean_aupr, mcc, jac_score,cohkap_score, f1, top_k]\n",
    "  df = pd.DataFrame(list1).T\n",
    "  df.columns = [\"org\", \"ds\", \"dec\", \"af_val\",\"num_layers\", \"epoch\", \"aggr\", \"var\",\"auc\", \"aupr\", \"mcc\", \"jac_score\",\"cohkap_score\", \"f1\", \"top_k\"]\n",
    "  #\n",
    "  return df,model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uELTSNhOKqhL"
   },
   "source": [
    "#DREAM5 - MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 680091,
     "status": "ok",
     "timestamp": 1707370951298,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "xTwJnGCdKrta",
    "outputId": "ce34ba1e-5253-4e84-e86e-835a08bb7c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current location : Insilico_basic_aug_data__dot_sum_3_200_F.sigmoid_sum_HypergraphConv\n",
      "/content/drive/MyDrive/Colab Notebooks/data/DREAM5/training data/basic_aug_data_Insilico_InSilicoSize100.pt\n",
      "current location : Ecoli_basic_aug_data__dot_sum_3_200_F.sigmoid_sum_HypergraphConv\n",
      "/content/drive/MyDrive/Colab Notebooks/data/DREAM5/training data/basic_aug_data_Ecoli_InSilicoSize100.pt\n",
      "current location : Scere_basic_aug_data__dot_sum_3_200_F.sigmoid_sum_HypergraphConv\n",
      "/content/drive/MyDrive/Colab Notebooks/data/DREAM5/training data/basic_aug_data_Scere_InSilicoSize100.pt\n",
      "        org               ds      dec     af_val num_layers epoch aggr  \\\n",
      "0  Insilico  basic_aug_data_  dot_sum  F.sigmoid          3   200  sum   \n",
      "0     Ecoli  basic_aug_data_  dot_sum  F.sigmoid          3   200  sum   \n",
      "0     Scere  basic_aug_data_  dot_sum  F.sigmoid          3   200  sum   \n",
      "\n",
      "              var       auc      aupr       mcc jac_score cohkap_score  \\\n",
      "0  HypergraphConv  0.878696  0.865001  0.659332  0.669505     0.645054   \n",
      "0  HypergraphConv  0.962675  0.953585   0.91431  0.918675     0.912763   \n",
      "0  HypergraphConv  0.980389  0.971988  0.956796  0.957792     0.956007   \n",
      "\n",
      "         f1     top_k  \n",
      "0   0.80204  0.822527  \n",
      "0  0.957614  0.956381  \n",
      "0  0.978441  0.978003  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"/content/drive/MyDrive/Colab Notebooks/data/DREAM5/training data/\"\n",
    "gold_std = \"/content/drive/MyDrive/Colab Notebooks/data/DREAM5/gold/test data/\"\n",
    "\n",
    "organism  = {\"Insilico\":  [\"InSilicoSize100\",\"net1_expression_data.tsv\",\"DREAM5_NetworkInference_GoldStandard_Network1 - in silico.tsv\"],\n",
    "                        # \"Saure\":  [\"InSilicoSize100\",\"net2_expression_data.tsv\",\"DREAM5_NetworkInference_GoldStandard_Network2 - S. aureus.txt\"],\n",
    "                        \"Ecoli\":  [\"InSilicoSize100\",\"net3_expression_data.tsv\",\"DREAM5_NetworkInference_GoldStandard_Network3 - E. coli.tsv\"],\n",
    "                        \"Scere\":  [\"InSilicoSize100\",\"net4_expression_data.tsv\",\"DREAM5_NetworkInference_GoldStandard_Network4 - S. cerevisiae.tsv\"]\n",
    "                            }\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"decoder\": [\"dot_sum\"],# substitute \"cos\" to use cos decoder\n",
    "    \"af\": [\"F.sigmoid\"],  # substitute \"F.silu\",\"F.tanh\" for activation functions\n",
    "    \"num_layers\" : [3],#2,4,5 #substitute layer count\n",
    "    \"variant\" : [\"HypergraphConv\"],#,\"SSGConv\",\"ChebConv\",\"ClusterGCNConv\" #substitute convolution layers\n",
    "    \"aggrs\" :[\"sum\"],# substitute \"add\"\n",
    "    \"epochs\" :[200]# substitute epochs 100,150,200,250\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "hidden1_channels=128\n",
    "hidden2_channels=64\n",
    "out_channels= 32\n",
    "num_layers = 4\n",
    "final_out = pd.DataFrame()\n",
    "\n",
    "ds_type =[\"basic_aug_data_\"] # Try different graph types : \"basic_TS_data_\",\"basic_TS_aug_data_\",\"basic_data_\"\n",
    "for org, files in organism.items():\n",
    "  # final_out = pd.DataFrame()\n",
    "  for ds in ds_type:\n",
    "    for dec in parameters.get('decoder'):\n",
    "      for lay_num in parameters.get('num_layers'):\n",
    "        for epoch in parameters.get('epochs'):\n",
    "          for af_val in parameters.get('af'):\n",
    "            for aggr in parameters.get('aggrs'):\n",
    "              for var in parameters.get('variant'):\n",
    "                # for dim in parameters.get('hc'):\n",
    "                  print(\"current location : \"+str(org)+'_'+str(ds)+'_'+str(dec)+'_'+str(lay_num)+'_'+str(epoch)+'_'+str(af_val)+'_'+str(aggr)+'_'+str(var))\n",
    "                  print(path+ds+org+\"_\"+files[0]+\".pt\")\n",
    "                  data = torch.load(path+ds+org+\"_\"+files[0]+\".pt\")#.cuda()\n",
    "\n",
    "                  #GSE1297 = torch.load(\"/content/drive/MyDrive/Colab Notebooks/DREAM challenge GCN GNN Experimentation/Human.pt\").cuda()\n",
    "                  temp,model = main_run(files[0],files[1],files[2],hidden1_channels,hidden2_channels,out_channels,data,org,ds,dec,af_val,lay_num,epoch,aggr,var)\n",
    "                  #pred = prediction(model, GSE1297,af_val,dec)\n",
    "                  final_out = final_out.append(temp)\n",
    "\n",
    "print(final_out)\n",
    "# final_out.to_excel('/content/drive/MyDrive/Colab Notebooks/DREAM challenge GCN GNN Experimentation/DREAM5_InsilicoSize100_'+str(org)+'_'+var+'Dimension_count.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fuUEUOpjL6T"
   },
   "source": [
    "##Version details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfxqRYBojGob"
   },
   "source": [
    "absl-py==1.4.0\n",
    "aiohttp==3.9.3\n",
    "aiosignal==1.3.1\n",
    "alabaster==0.7.16\n",
    "albumentations==1.3.1\n",
    "altair==4.2.2\n",
    "annotated-types==0.6.0\n",
    "anyio==3.7.1\n",
    "appdirs==1.4.4\n",
    "argon2-cffi==23.1.0\n",
    "argon2-cffi-bindings==21.2.0\n",
    "array-record==0.5.0\n",
    "arviz==0.15.1\n",
    "astropy==5.3.4\n",
    "astunparse==1.6.3\n",
    "async-timeout==4.0.3\n",
    "atpublic==4.0\n",
    "attrs==23.2.0\n",
    "audioread==3.0.1\n",
    "autograd==1.6.2\n",
    "Babel==2.14.0\n",
    "backcall==0.2.0\n",
    "beautifulsoup4==4.12.3\n",
    "bidict==0.22.1\n",
    "bigframes==0.20.0\n",
    "bleach==6.1.0\n",
    "blinker==1.4\n",
    "blis==0.7.11\n",
    "blosc2==2.0.0\n",
    "bokeh==3.3.4\n",
    "bqplot==0.12.42\n",
    "branca==0.7.1\n",
    "build==1.0.3\n",
    "CacheControl==0.14.0\n",
    "cachetools==5.3.2\n",
    "catalogue==2.0.10\n",
    "certifi==2024.2.2\n",
    "cffi==1.16.0\n",
    "chardet==5.2.0\n",
    "charset-normalizer==3.3.2\n",
    "chex==0.1.7\n",
    "click==8.1.7\n",
    "click-plugins==1.1.1\n",
    "cligj==0.7.2\n",
    "cloudpathlib==0.16.0\n",
    "cloudpickle==2.2.1\n",
    "cmake==3.27.9\n",
    "cmdstanpy==1.2.0\n",
    "colorcet==3.0.1\n",
    "colorlover==0.3.0\n",
    "colour==0.1.5\n",
    "community==1.0.0b1\n",
    "confection==0.1.4\n",
    "cons==0.4.6\n",
    "contextlib2==21.6.0\n",
    "contourpy==1.2.0\n",
    "cryptography==42.0.2\n",
    "cufflinks==0.17.3\n",
    "cupy-cuda12x==12.2.0\n",
    "cvxopt==1.3.2\n",
    "cvxpy==1.3.3\n",
    "cycler==0.12.1\n",
    "cymem==2.0.8\n",
    "Cython==3.0.8\n",
    "dask==2023.8.1\n",
    "datascience==0.17.6\n",
    "db-dtypes==1.2.0\n",
    "dbus-python==1.2.18\n",
    "debugpy==1.6.6\n",
    "decorator==4.4.2\n",
    "defusedxml==0.7.1\n",
    "diskcache==5.6.3\n",
    "distributed==2023.8.1\n",
    "distro==1.7.0\n",
    "dlib==19.24.2\n",
    "dm-tree==0.1.8\n",
    "docutils==0.18.1\n",
    "dopamine-rl==4.0.6\n",
    "duckdb==0.9.2\n",
    "earthengine-api==0.1.388\n",
    "easydict==1.11\n",
    "ecos==2.0.12\n",
    "editdistance==0.6.2\n",
    "eerepr==0.0.4\n",
    "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
    "entrypoints==0.4\n",
    "et-xmlfile==1.1.0\n",
    "etils==1.6.0\n",
    "etuples==0.3.9\n",
    "exceptiongroup==1.2.0\n",
    "fastai==2.7.14\n",
    "fastcore==1.5.29\n",
    "fastdownload==0.0.7\n",
    "fastjsonschema==2.19.1\n",
    "fastprogress==1.0.3\n",
    "fastrlock==0.8.2\n",
    "filelock==3.13.1\n",
    "fiona==1.9.5\n",
    "firebase-admin==5.3.0\n",
    "Flask==2.2.5\n",
    "flatbuffers==23.5.26\n",
    "flax==0.8.0\n",
    "folium==0.14.0\n",
    "fonttools==4.47.2\n",
    "frozendict==2.4.0\n",
    "frozenlist==1.4.1\n",
    "fsspec==2023.6.0\n",
    "future==0.18.3\n",
    "gast==0.5.4\n",
    "gcsfs==2023.6.0\n",
    "GDAL==3.6.4\n",
    "gdown==4.7.3\n",
    "geemap==0.30.4\n",
    "gensim==4.3.2\n",
    "geocoder==1.38.1\n",
    "geographiclib==2.0\n",
    "geopandas==0.13.2\n",
    "geopy==2.3.0\n",
    "gin-config==0.5.0\n",
    "glob2==0.7\n",
    "google==2.0.3\n",
    "google-ai-generativelanguage==0.4.0\n",
    "google-api-core==2.11.1\n",
    "google-api-python-client==2.84.0\n",
    "google-auth==2.17.3\n",
    "google-auth-httplib2==0.1.1\n",
    "google-auth-oauthlib==1.2.0\n",
    "google-cloud-aiplatform==1.39.0\n",
    "google-cloud-bigquery==3.12.0\n",
    "google-cloud-bigquery-connection==1.12.1\n",
    "google-cloud-bigquery-storage==2.24.0\n",
    "google-cloud-core==2.3.3\n",
    "google-cloud-datastore==2.15.2\n",
    "google-cloud-firestore==2.11.1\n",
    "google-cloud-functions==1.13.3\n",
    "google-cloud-iam==2.14.0\n",
    "google-cloud-language==2.9.1\n",
    "google-cloud-resource-manager==1.12.0\n",
    "google-cloud-storage==2.8.0\n",
    "google-cloud-translate==3.11.3\n",
    "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=1d59f6b64dadf8ce0c1c2be96eab7ab76eb09ec2ef3192d0feb07e15221763b3\n",
    "google-crc32c==1.5.0\n",
    "google-generativeai==0.3.2\n",
    "google-pasta==0.2.0\n",
    "google-resumable-media==2.7.0\n",
    "googleapis-common-protos==1.62.0\n",
    "googledrivedownloader==0.4\n",
    "graphviz==0.20.1\n",
    "greenlet==3.0.3\n",
    "grpc-google-iam-v1==0.13.0\n",
    "grpcio==1.60.1\n",
    "grpcio-status==1.48.2\n",
    "gspread==3.4.2\n",
    "gspread-dataframe==3.3.1\n",
    "gym==0.25.2\n",
    "gym-notices==0.0.8\n",
    "h5netcdf==1.3.0\n",
    "h5py==3.9.0\n",
    "holidays==0.41\n",
    "holoviews==1.17.1\n",
    "html5lib==1.1\n",
    "httpimport==1.3.1\n",
    "httplib2==0.22.0\n",
    "huggingface-hub==0.20.3\n",
    "humanize==4.7.0\n",
    "hyperopt==0.2.7\n",
    "ibis-framework==7.1.0\n",
    "idna==3.6\n",
    "imageio==2.31.6\n",
    "imageio-ffmpeg==0.4.9\n",
    "imagesize==1.4.1\n",
    "imbalanced-learn==0.10.1\n",
    "imgaug==0.4.0\n",
    "importlib-metadata==7.0.1\n",
    "importlib-resources==6.1.1\n",
    "imutils==0.5.4\n",
    "inflect==7.0.0\n",
    "iniconfig==2.0.0\n",
    "install==1.3.5\n",
    "intel-openmp==2023.2.3\n",
    "ipyevents==2.0.2\n",
    "ipyfilechooser==0.6.0\n",
    "ipykernel==5.5.6\n",
    "ipyleaflet==0.18.2\n",
    "ipython==7.34.0\n",
    "ipython-genutils==0.2.0\n",
    "ipython-sql==0.5.0\n",
    "ipytree==0.2.2\n",
    "ipywidgets==7.7.1\n",
    "itsdangerous==2.1.2\n",
    "jax==0.4.23\n",
    "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=8e42000672599e7ec0ea7f551acfcc95dcdd0e22b05a1d1f12f97b56a9fce4a8\n",
    "jeepney==0.7.1\n",
    "jieba==0.42.1\n",
    "Jinja2==3.1.3\n",
    "joblib==1.3.2\n",
    "jsonpickle==3.0.2\n",
    "jsonschema==4.19.2\n",
    "jsonschema-specifications==2023.12.1\n",
    "jupyter-client==6.1.12\n",
    "jupyter-console==6.1.0\n",
    "jupyter-server==1.24.0\n",
    "jupyter_core==5.7.1\n",
    "jupyterlab-widgets==3.0.9\n",
    "jupyterlab_pygments==0.3.0\n",
    "kaggle==1.5.16\n",
    "kagglehub==0.1.8\n",
    "keras==2.15.0\n",
    "keyring==23.5.0\n",
    "kiwisolver==1.4.5\n",
    "langcodes==3.3.0\n",
    "launchpadlib==1.10.16\n",
    "lazr.restfulclient==0.14.4\n",
    "lazr.uri==1.0.6\n",
    "lazy_loader==0.3\n",
    "libclang==16.0.6\n",
    "librosa==0.10.1\n",
    "lida==0.0.10\n",
    "lightgbm==4.1.0\n",
    "linkify-it-py==2.0.2\n",
    "llmx==0.0.15a0\n",
    "llvmlite==0.41.1\n",
    "locket==1.0.0\n",
    "logical-unification==0.4.6\n",
    "lxml==4.9.4\n",
    "malloy==2023.1067\n",
    "Markdown==3.5.2\n",
    "markdown-it-py==3.0.0\n",
    "MarkupSafe==2.1.5\n",
    "matplotlib==3.7.1\n",
    "matplotlib-inline==0.1.6\n",
    "matplotlib-venn==0.11.10\n",
    "mdit-py-plugins==0.4.0\n",
    "mdurl==0.1.2\n",
    "miniKanren==1.0.3\n",
    "missingno==0.5.2\n",
    "mistune==0.8.4\n",
    "mizani==0.9.3\n",
    "mkl==2023.2.0\n",
    "ml-dtypes==0.2.0\n",
    "mlxtend==0.22.0\n",
    "more-itertools==10.1.0\n",
    "moviepy==1.0.3\n",
    "mpmath==1.3.0\n",
    "msgpack==1.0.7\n",
    "multidict==6.0.5\n",
    "multipledispatch==1.0.0\n",
    "multitasking==0.0.11\n",
    "murmurhash==1.0.10\n",
    "music21==9.1.0\n",
    "natsort==8.4.0\n",
    "nbclassic==1.0.0\n",
    "nbclient==0.9.0\n",
    "nbconvert==6.5.4\n",
    "nbformat==5.9.2\n",
    "nest-asyncio==1.6.0\n",
    "networkx==3.2.1\n",
    "nibabel==4.0.2\n",
    "nltk==3.8.1\n",
    "notebook==6.5.5\n",
    "notebook_shim==0.2.3\n",
    "numba==0.58.1\n",
    "numexpr==2.9.0\n",
    "numpy==1.23.5\n",
    "numpy-ml==0.1.2\n",
    "oauth2client==4.1.3\n",
    "oauthlib==3.2.2\n",
    "opencv-contrib-python==4.8.0.76\n",
    "opencv-python==4.8.0.76\n",
    "opencv-python-headless==4.9.0.80\n",
    "openpyxl==3.1.2\n",
    "opt-einsum==3.3.0\n",
    "optax==0.1.8\n",
    "orbax-checkpoint==0.4.4\n",
    "osqp==0.6.2.post8\n",
    "packaging==23.2\n",
    "pandas==1.5.3\n",
    "pandas-datareader==0.10.0\n",
    "pandas-gbq==0.19.2\n",
    "pandas-stubs==1.5.3.230304\n",
    "pandocfilters==1.5.1\n",
    "panel==1.3.8\n",
    "param==2.0.2\n",
    "parso==0.8.3\n",
    "parsy==2.1\n",
    "partd==1.4.1\n",
    "pathlib==1.0.1\n",
    "patsy==0.5.6\n",
    "peewee==3.17.0\n",
    "pexpect==4.9.0\n",
    "pickleshare==0.7.5\n",
    "Pillow==9.4.0\n",
    "pins==0.8.4\n",
    "pip-tools==6.13.0\n",
    "platformdirs==4.2.0\n",
    "plotly==5.15.0\n",
    "plotnine==0.12.4\n",
    "pluggy==1.4.0\n",
    "polars==0.20.2\n",
    "pooch==1.8.0\n",
    "portpicker==1.5.2\n",
    "prefetch-generator==1.0.3\n",
    "preshed==3.0.9\n",
    "prettytable==3.9.0\n",
    "proglog==0.1.10\n",
    "progressbar2==4.2.0\n",
    "prometheus-client==0.19.0\n",
    "promise==2.3\n",
    "prompt-toolkit==3.0.43\n",
    "prophet==1.1.5\n",
    "proto-plus==1.23.0\n",
    "protobuf==3.20.3\n",
    "psutil==5.9.5\n",
    "psycopg2==2.9.9\n",
    "ptyprocess==0.7.0\n",
    "py-cpuinfo==9.0.0\n",
    "py4j==0.10.9.7\n",
    "pyarrow==10.0.1\n",
    "pyarrow-hotfix==0.6\n",
    "pyasn1==0.5.1\n",
    "pyasn1-modules==0.3.0\n",
    "pycocotools==2.0.7\n",
    "pycparser==2.21\n",
    "pyct==0.5.0\n",
    "pydantic==2.6.0\n",
    "pydantic_core==2.16.1\n",
    "pydata-google-auth==1.8.2\n",
    "pydot==1.4.2\n",
    "pydot-ng==2.0.0\n",
    "pydotplus==2.0.2\n",
    "PyDrive==1.3.1\n",
    "PyDrive2==1.6.3\n",
    "pyerfa==2.0.1.1\n",
    "pygame==2.5.2\n",
    "Pygments==2.16.1\n",
    "PyGObject==3.42.1\n",
    "PyJWT==2.3.0\n",
    "pymc==5.7.2\n",
    "pymystem3==0.2.0\n",
    "PyOpenGL==3.1.7\n",
    "pyOpenSSL==24.0.0\n",
    "pyparsing==3.1.1\n",
    "pyperclip==1.8.2\n",
    "pyproj==3.6.1\n",
    "pyproject_hooks==1.0.0\n",
    "pyshp==2.3.1\n",
    "PySocks==1.7.1\n",
    "pytensor==2.14.2\n",
    "pytest==7.4.4\n",
    "python-apt==0.0.0\n",
    "python-box==7.1.1\n",
    "python-dateutil==2.8.2\n",
    "python-louvain==0.16\n",
    "python-slugify==8.0.3\n",
    "python-utils==3.8.2\n",
    "pytz==2023.4\n",
    "pyviz_comms==3.0.1\n",
    "PyWavelets==1.5.0\n",
    "PyYAML==6.0.1\n",
    "pyzmq==23.2.1\n",
    "qdldl==0.1.7.post0\n",
    "qudida==0.0.4\n",
    "ratelim==0.1.6\n",
    "referencing==0.33.0\n",
    "regex==2023.12.25\n",
    "requests==2.31.0\n",
    "requests-oauthlib==1.3.1\n",
    "requirements-parser==0.5.0\n",
    "rich==13.7.0\n",
    "rpds-py==0.17.1\n",
    "rpy2==3.4.2\n",
    "rsa==4.9\n",
    "safetensors==0.4.2\n",
    "scikit-image==0.19.3\n",
    "scikit-learn==1.2.2\n",
    "scipy==1.11.4\n",
    "scooby==0.9.2\n",
    "scs==3.2.4.post1\n",
    "seaborn==0.13.1\n",
    "SecretStorage==3.3.1\n",
    "Send2Trash==1.8.2\n",
    "sentencepiece==0.1.99\n",
    "shapely==2.0.2\n",
    "six==1.16.0\n",
    "sklearn-pandas==2.2.0\n",
    "smart-open==6.4.0\n",
    "sniffio==1.3.0\n",
    "snowballstemmer==2.2.0\n",
    "sortedcontainers==2.4.0\n",
    "soundfile==0.12.1\n",
    "soupsieve==2.5\n",
    "soxr==0.3.7\n",
    "spacy==3.7.2\n",
    "spacy-legacy==3.0.12\n",
    "spacy-loggers==1.0.5\n",
    "Sphinx==5.0.2\n",
    "sphinxcontrib-applehelp==1.0.8\n",
    "sphinxcontrib-devhelp==1.0.6\n",
    "sphinxcontrib-htmlhelp==2.0.5\n",
    "sphinxcontrib-jsmath==1.0.1\n",
    "sphinxcontrib-qthelp==1.0.7\n",
    "sphinxcontrib-serializinghtml==1.1.10\n",
    "SQLAlchemy==2.0.25\n",
    "sqlglot==19.9.0\n",
    "sqlparse==0.4.4\n",
    "srsly==2.4.8\n",
    "stanio==0.3.0\n",
    "statsmodels==0.14.1\n",
    "sympy==1.12\n",
    "tables==3.8.0\n",
    "tabulate==0.9.0\n",
    "tbb==2021.11.0\n",
    "tblib==3.0.0\n",
    "tenacity==8.2.3\n",
    "tensorboard==2.15.1\n",
    "tensorboard-data-server==0.7.2\n",
    "tensorflow==2.15.0\n",
    "tensorflow-datasets==4.9.4\n",
    "tensorflow-estimator==2.15.0\n",
    "tensorflow-gcs-config==2.15.0\n",
    "tensorflow-hub==0.16.1\n",
    "tensorflow-io-gcs-filesystem==0.35.0\n",
    "tensorflow-metadata==1.14.0\n",
    "tensorflow-probability==0.23.0\n",
    "tensorstore==0.1.45\n",
    "termcolor==2.4.0\n",
    "terminado==0.18.0\n",
    "text-unidecode==1.3\n",
    "textblob==0.17.1\n",
    "tf-keras==2.15.0\n",
    "tf-slim==1.1.0\n",
    "thinc==8.2.2\n",
    "threadpoolctl==3.2.0\n",
    "tifffile==2024.1.30\n",
    "tinycss2==1.2.1\n",
    "tokenizers==0.15.1\n",
    "toml==0.10.2\n",
    "tomli==2.0.1\n",
    "toolz==0.12.1\n",
    "torch @ https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=0d4e8c52a1fcf5ed6cfc256d9a370fcf4360958fc79d0b08a51d55e70914df46\n",
    "torch_geometric==2.4.0\n",
    "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=676bda4042734eda99bc59b2d7f761f345d3cde0cad492ad34e3aefde688c6d8\n",
    "torchdata==0.7.0\n",
    "torchsummary==1.5.1\n",
    "torchtext==0.16.0\n",
    "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=e76e78d0ad43636c9884b3084ffaea8a8b61f21129fbfa456a5fe734f0affea9\n",
    "tornado==6.3.2\n",
    "tqdm==4.66.1\n",
    "traitlets==5.7.1\n",
    "traittypes==0.2.1\n",
    "transformers==4.35.2\n",
    "triton==2.1.0\n",
    "tweepy==4.14.0\n",
    "typer==0.9.0\n",
    "types-pytz==2023.4.0.20240130\n",
    "types-setuptools==69.0.0.20240125\n",
    "typing_extensions==4.9.0\n",
    "tzlocal==5.2\n",
    "uc-micro-py==1.0.2\n",
    "uritemplate==4.1.1\n",
    "urllib3==2.0.7\n",
    "vega-datasets==0.9.0\n",
    "wadllib==1.3.6\n",
    "wasabi==1.1.2\n",
    "wcwidth==0.2.13\n",
    "weasel==0.3.4\n",
    "webcolors==1.13\n",
    "webencodings==0.5.1\n",
    "websocket-client==1.7.0\n",
    "Werkzeug==3.0.1\n",
    "widgetsnbextension==3.6.6\n",
    "wordcloud==1.9.3\n",
    "wrapt==1.14.1\n",
    "xarray==2023.7.0\n",
    "xarray-einstats==0.7.0\n",
    "xgboost==2.0.3\n",
    "xlrd==2.0.1\n",
    "xxhash==3.4.1\n",
    "xyzservices==2023.10.1\n",
    "yarl==1.9.4\n",
    "yellowbrick==1.5\n",
    "yfinance==0.2.36\n",
    "zict==3.0.0\n",
    "zipp==3.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0iYcOmalx_a"
   },
   "source": [
    "#DREAM4 - MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.xgraph.method import SubgraphX\n",
    "from dig.xgraph.method import GNN_LRP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707369410263,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "RZxMYQMPoMP6"
   },
   "outputs": [],
   "source": [
    "''' CODE TO RUN AFTER PREPROCESSING '''\n",
    "def main_run(folder_name,file_gold,hidden2_channels,out_channels,data,org,ds,dec,af_val,num_layers,epoch,aggr,var):\n",
    "  auprs =0\n",
    "  aucs =0\n",
    "\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "  for i in range(10) :\n",
    "    # print(\"i is : \", i)\n",
    "    split = T.RandomLinkSplit(\n",
    "        num_val=0.2,\n",
    "        num_test=0.3,\n",
    "        is_undirected=False,\n",
    "        add_negative_train_samples=True,\n",
    "        key=\"edge_label\"\n",
    "    )\n",
    "\n",
    "    train_data, val_data, test_data = split(data)\n",
    "\n",
    "# 데이터 디바이스 이동\n",
    "    train_data.x = train_data.x.to(device)\n",
    "    train_data.edge_index = train_data.edge_index.to(device)\n",
    "    train_data.edge_label = train_data.edge_label.to(device)\n",
    "    train_data.edge_label_index = train_data.edge_label_index.to(device)\n",
    "\n",
    "    val_data.x = val_data.x.to(device)\n",
    "    val_data.edge_index = val_data.edge_index.to(device)\n",
    "    val_data.edge_label = val_data.edge_label.to(device)\n",
    "    val_data.edge_label_index = val_data.edge_label_index.to(device)\n",
    "\n",
    "    test_data.x = test_data.x.to(device)\n",
    "    test_data.edge_index = test_data.edge_index.to(device)\n",
    "    test_data.edge_label = test_data.edge_label.to(device)\n",
    "    test_data.edge_label_index = test_data.edge_label_index.to(device)\n",
    "\n",
    "    index=(train_data.edge_label == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    ################\n",
    "\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    #####################\n",
    "\n",
    "    ''' OLD CODE'''\n",
    "    in_channels=data.num_features\n",
    "\n",
    "    model =  Net(in_channels, hidden1_channels, hidden2_channels, out_channels,dec,af_val,num_layers,epoch,aggr,var).to(device)#Net(data.num_features, data.num_features, 128, 64).to(device) #self, in_channels, hidden1_channels, hidden2_channels,out_channels\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)#RMSprop(params=model.parameters())#\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion,epoch,af_val,dec).to(device)\n",
    "\n",
    "    test_auc, precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k = eval_link_predictor(model, test_data,af_val,dec)\n",
    "    aucs = aucs+test_auc\n",
    "    aupr = auc(recall, precision)\n",
    "    auprs=auprs+aupr\n",
    "\n",
    "    #####\n",
    "    #  # 모델 출력 계산 (logits)\n",
    "    # logits = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    # logits = logits.to(device)\n",
    "\n",
    "    #   # 로짓 출력 확인\n",
    "    # print(\"Logits Shape:\", logits.shape)  # 예: (num_test_edges, 1)\n",
    "\n",
    "    ######\n",
    "\n",
    "\n",
    "\n",
    "  mean_auc = float(aucs/10)\n",
    "  mean_aupr = float(auprs/10)\n",
    "\n",
    "\n",
    "  list1 = [org, ds, dec, af_val,num_layers, epoch, aggr, var,mean_auc, mean_aupr, mcc, jac_score,cohkap_score, f1, top_k]\n",
    "  df = pd.DataFrame(list1).T\n",
    "  df.columns = [\"org\", \"ds\", \"dec\", \"af_val\",\"num_layers\", \"epoch\", \"aggr\", \"var\",\"auc\", \"aupr\", \"mcc\", \"jac_score\",\"cohkap_score\", \"f1\", \"top_k\"]\n",
    "\n",
    "# #########################\n",
    "# # SubGraphX\n",
    "\n",
    "#   explainer = SubgraphX(model, num_classes=2, device=device,\n",
    "#                       explain_graph=False, reward_method='nc_mc_l_shapley')\n",
    "# ########################\n",
    "###########################\n",
    "# GNN-LRP\n",
    "\n",
    "  explainer = GNN_LRP(model, explain_graph=True)\n",
    "\n",
    "\n",
    "  ###################\n",
    "\n",
    "    # --- Set the Sparsity to 0. ---\n",
    "  sparsity = 0.5\n",
    "  num_classes = 2\n",
    "\n",
    "  # --- Create data collector and explanation processor ---\n",
    "\n",
    "  x_collector = XCollector(sparsity)\n",
    "  # x_processor = ExplanationProcessor(model=model, device=device)\n",
    "  #####################\n",
    "\n",
    "\n",
    "  for index, data in enumerate(test_loader):\n",
    "    print(f'explain graph line {test_loader.dataset.indices[index] + 2}')\n",
    "    data.to(device)\n",
    "\n",
    "    if torch.isnan(data.edge_label[0].squeeze()):\n",
    "        continue\n",
    "\n",
    "    walks, masks, related_preds = explainer(data.x, data.edge_index, sparsity=sparsity, num_classes=num_classes)\n",
    "\n",
    "    x_collector.collect_data(masks, related_preds, data.edge_label[0].squeeze().long().item())\n",
    "\n",
    "    # if you only have the edge masks without related_pred, please feed sparsity controlled mask to\n",
    "    # obtain the result: x_processor(data, masks, x_collector)\n",
    "\n",
    "    if index >= 1:\n",
    "        break\n",
    "\n",
    "##############################\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220182,
     "status": "ok",
     "timestamp": 1707369630439,
     "user": {
      "displayName": "Emma Law",
      "userId": "03519105856398437512"
     },
     "user_tz": -330
    },
    "id": "afxrWw0Ol04S",
    "outputId": "ebb361b1-1262-45b5-f9e1-52055aba60c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current location : Ecoli1_basic_TS_aug_data__dot_sum_3_200_F.silu_sum_HypergraphConv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m                   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent location : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(org)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(ds)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(dec)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(lay_num)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(af_val)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(aggr)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(var))\n\u001b[1;32m     36\u001b[0m                   data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/DREAM4/DREAM4_InSilico_Size100/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mds\u001b[38;5;241m+\u001b[39morg\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfiles[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#.cuda()\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m                   temp \u001b[38;5;241m=\u001b[39m \u001b[43mmain_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden2_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43morg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43maf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlay_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43maggr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m                   final_out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final_out, temp], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_out)\n",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m, in \u001b[0;36mmain_run\u001b[0;34m(folder_name, file_gold, hidden2_channels, out_channels, data, org, ds, dec, af_val, num_layers, epoch, aggr, var)\u001b[0m\n\u001b[1;32m     41\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\u001b[38;5;66;03m#RMSprop(params=model.parameters())#\u001b[39;00m\n\u001b[1;32m     42\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_link_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43maf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m test_auc, precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k \u001b[38;5;241m=\u001b[39m eval_link_predictor(model, test_data,af_val,dec)\n\u001b[1;32m     46\u001b[0m aucs \u001b[38;5;241m=\u001b[39m aucs\u001b[38;5;241m+\u001b[39mtest_auc\n",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m, in \u001b[0;36mtrain_link_predictor\u001b[0;34m(model, train_data, val_data, optimizer, criterion, n_epochs, af_val, dec)\u001b[0m\n\u001b[1;32m     76\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     77\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 79\u001b[0m     val_auc,precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k \u001b[38;5;241m=\u001b[39m \u001b[43meval_link_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43maf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 101\u001b[0m, in \u001b[0;36meval_link_predictor\u001b[0;34m(model, data, af_val, dec)\u001b[0m\n\u001b[1;32m     99\u001b[0m jac_score \u001b[38;5;241m=\u001b[39m jaccard_score(actual, pred)\n\u001b[1;32m    100\u001b[0m cohkap_score \u001b[38;5;241m=\u001b[39m cohen_kappa_score(actual, pred)\n\u001b[0;32m--> 101\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m top_k \u001b[38;5;241m=\u001b[39m top_k_accuracy_score(actual, pred, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m auc,precision, recall,fpr, tpr, mcc, jac_score, cohkap_score, f1, top_k\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1293\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1114\u001b[0m     {\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1141\u001b[0m ):\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1485\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1306\u001b[0m     {\n\u001b[1;32m   1307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1335\u001b[0m ):\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;124;03m    np.float64(0.12...)\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1485\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1793\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1793\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1800\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1801\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:557\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSamplewise metrics are not available outside of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel classification.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m     )\n\u001b[1;32m    556\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m--> 557\u001b[0m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m y_true \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_true)\n\u001b[1;32m    559\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:98\u001b[0m, in \u001b[0;36mLabelEncoder.fit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Fitted label encoder.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_encode.py:46\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_python(\n\u001b[1;32m     43\u001b[0m         values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_np\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/sklearn/utils/_encode.py:54\u001b[0m, in \u001b[0;36m_unique_np\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unique_np\u001b[39m(values, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values for numpy arrays that correctly\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    accounts for nans. See `_unique` documentation for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     inverse, counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_counts:\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:144\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unique_dispatcher\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m                        return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ar,)\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_unique_dispatcher)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    146\u001b[0m            return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    Find the unique elements of an array.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gold_std = \"./data/DREAM4/gold_std/\"\n",
    "\n",
    "InsilicoSize100_org  = {\"Ecoli1\":  [\"InSilicoSize100\",\"insilico_size100_1_knockdowns.tsv\",\"insilico_size100_1_knockouts.tsv\",\"insilico_size100_1_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_1.tsv\"],\n",
    "                       \"Ecoli2\":  [\"InSilicoSize100\",\"insilico_size100_2_knockdowns.tsv\",\"insilico_size100_2_knockouts.tsv\",\"insilico_size100_2_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_2.tsv\"],\n",
    "                       \"Yeast1\":  [\"InSilicoSize100\",\"insilico_size100_3_knockdowns.tsv\",\"insilico_size100_3_knockouts.tsv\",\"insilico_size100_3_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_3.tsv\"],\n",
    "                       \"Yeast2\":  [\"InSilicoSize100\",\"insilico_size100_4_knockdowns.tsv\",\"insilico_size100_4_knockouts.tsv\",\"insilico_size100_4_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_4.tsv\"],\n",
    "                       \"Yeast3\":  [\"InSilicoSize100\",\"insilico_size100_5_knockdowns.tsv\",\"insilico_size100_5_knockouts.tsv\",\"insilico_size100_5_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_5.tsv\"]\n",
    "                            }\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"decoder\": [\"dot_sum\"],# substitute \"cos\" to use cos decoder\n",
    "    \"af\": [\"F.silu\"],  # substitute \"F.sigmoid\",\"F.tanh\" for activation functions\n",
    "    \"num_layers\" : [3],#2,4,5 #substitute layer count\n",
    "    \"variant\" : [\"HypergraphConv\"],#,\"SSGConv\",\"ChebConv\",\"ClusterGCNConv\" #substitute convolution layers\n",
    "    \"aggrs\" :[\"sum\"],# substitute \"add\"\n",
    "    \"epochs\" :[200]# substitute epochs 100,150,200,250\n",
    "               }\n",
    "\n",
    "hidden1_channels=128\n",
    "hidden2_channels=64\n",
    "out_channels= 32\n",
    "num_layers = 4\n",
    "final_out = pd.DataFrame()\n",
    "\n",
    "ds_type =[\"basic_TS_aug_data_\"]#,] # Try different graph types : \"basic_TS_data_\",\"basic_TS_aug_data_\",\"basic_data_\"\n",
    "for org, files in InsilicoSize100_org.items():\n",
    "  for ds in ds_type:\n",
    "    for dec in parameters.get('decoder'):\n",
    "      for lay_num in parameters.get('num_layers'):\n",
    "        for epoch in parameters.get('epochs'):\n",
    "          for af_val in parameters.get('af'):\n",
    "            for aggr in parameters.get('aggrs'):\n",
    "              for var in parameters.get('variant'):\n",
    "                  print(\"current location : \"+str(org)+'_'+str(ds)+'_'+str(dec)+'_'+str(lay_num)+'_'+str(epoch)+'_'+str(af_val)+'_'+str(aggr)+'_'+str(var))\n",
    "                  data = torch.load(\"./data/DREAM4/DREAM4_InSilico_Size100/\"+ds+org+\"_\"+files[0]+\".pt\")#.cuda()\n",
    "                  temp = main_run(files[0],files[4],hidden2_channels,out_channels,data,org,ds,dec,af_val,lay_num,epoch,aggr,var)\n",
    "                  final_out = pd.concat([final_out, temp], ignore_index=True)\n",
    "\n",
    "print(final_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SubGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.xgraph.method import SubgraphX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = SubgraphX(model, num_classes=4, device=device,\n",
    "                      explain_graph=False, reward_method='nc_mc_l_shapley')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNADKtmNGWcnrh8BvYUZmTs",
   "collapsed_sections": [
    "G_J0CLolKV-K",
    "k5LNfVBRKgcB",
    "8Vg4_mbLcRel",
    "uELTSNhOKqhL",
    "_fuUEUOpjL6T",
    "Q0iYcOmalx_a"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GRNXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
